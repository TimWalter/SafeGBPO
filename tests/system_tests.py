import wandb
from main import run_experiment

from conf.envs import *
from conf.safeguard import *
from conf.learning_algorithms import *

wandb.login(key="")

experiment_queue = [
    Experiment(num_runs=1,
               learning_algorithm=PPOConfig(),
               env=BalancePendulumConfig(),
               safeguard=None,
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SACConfig(),
               env=BalancePendulumConfig(),
               safeguard=None,
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalancePendulumConfig(),
               safeguard=None,
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SACConfig(),
               env=BalancePendulumConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=PPOConfig(),
               env=BalancePendulumConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalancePendulumConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SACConfig(),
               env=BalanceQuadrotorConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=PPOConfig(),
               env=BalanceQuadrotorConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalanceQuadrotorConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=True),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalanceCartPoleConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=SwingUpCartPoleConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=ManageHouseholdConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=NavigateSeekerConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=NavigateQuadrotorConfig(),
               safeguard=BoundaryProjectionConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalanceQuadrotorConfig(),
               safeguard=RayMaskConfig(),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
    Experiment(num_runs=1,
               learning_algorithm=SHACConfig(),
               env=BalanceQuadrotorConfig(),
               safeguard=RayMaskConfig(passthrough=True),
               interactions=15_000,
               eval_freq=5_000,
               fast_eval=False),
Experiment(num_runs=1,
                   learning_algorithm=SHACConfig(),
                   env=BalanceQuadrotorConfig(),
                   safeguard=RayMaskConfig(zonotopic_approximation=False),
                   interactions=15_000,
                   eval_freq=5_000,
                   fast_eval=False),
]

for i, experiment in enumerate(experiment_queue):
    print(f"[STATUS] Running experiment [{i + 1}/{len(experiment_queue)}]")
    for j in range(experiment.num_runs):
        run_experiment(experiment)
