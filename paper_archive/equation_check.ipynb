{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T12:34:25.578883Z",
     "start_time": "2025-09-29T12:34:23.682774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import sympy as sp\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "sp.init_printing(use_unicode=True)"
   ],
   "id": "fe58d2e4731e5f43",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Second non-numbered equation",
   "id": "a8e5e33ccde78add"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.486158Z",
     "start_time": "2025-09-29T09:19:46.345060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters (theta is 2D, requires gradients)\n",
    "theta = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# Define state s_t(theta) ∈ R^2\n",
    "s1 = theta[0] ** 2 + theta[1]\n",
    "s2 = torch.sin(theta[0])\n",
    "s_t = torch.stack([s1, s2])\n",
    "\n",
    "# Define action a_t(theta) ∈ R^1\n",
    "a_t = torch.tensor([theta[0] * theta[1]])\n",
    "\n",
    "\n",
    "# Reward function\n",
    "def r_fn(s, a):\n",
    "    return s[0] * s[1] + a[0] ** 2\n",
    "\n",
    "\n",
    "# Reward r(s, a) scalar\n",
    "r = r_fn(s_t, a_t)\n",
    "\n",
    "# Automatic gradient via PyTorch\n",
    "r.backward()\n",
    "grad_autodiff = theta.grad.clone()\n",
    "theta.grad.zero_()\n",
    "\n",
    "print(\"Automatic gradient:\", grad_autodiff)\n",
    "\n",
    "dr_ds = torch.autograd.functional.jacobian(lambda s: r_fn(s, a_t), s_t)\n",
    "dr_da = torch.autograd.functional.jacobian(lambda a: r_fn(s_t, a), a_t)\n",
    "ds_dtheta = torch.autograd.functional.jacobian(lambda th: torch.stack([th[0] ** 2 + th[1], torch.sin(th[0])]), theta)\n",
    "da_dtheta = torch.autograd.functional.jacobian(lambda th: torch.tensor([th[0] * th[1]]), theta)\n",
    "grad_formula = dr_ds @ ds_dtheta + dr_da @ da_dtheta\n",
    "\n",
    "print(\"Formula gradient:\", grad_formula)"
   ],
   "id": "41f56f37bf739ac9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic gradient: tensor([3.3038, 0.8415])\n",
      "Formula gradient: tensor([3.3038, 0.8415])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222994/2670516345.py:10: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  a_t = torch.tensor([theta[0] * theta[1]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eq. 11",
   "id": "3af1a4013df8dc2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.500258Z",
     "start_time": "2025-09-29T09:19:46.493004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input action\n",
    "a_i = torch.tensor([1.5], requires_grad=True)\n",
    "\n",
    "# a_s as function of a\n",
    "a_s = torch.sin(a_i)\n",
    "\n",
    "# Next state s_{i+1} as function of a_s\n",
    "s_next = a_s ** 2\n",
    "\n",
    "\n",
    "# Reward depends on both a_s and s_next\n",
    "def r_fn(a_s, s_next):\n",
    "    return a_s * s_next + a_s ** 3  # scalar\n",
    "\n",
    "\n",
    "r = r_fn(a_s, s_next)\n",
    "\n",
    "# ---- Ground truth (autograd) ----\n",
    "r.backward()\n",
    "grad_autodiff = a_i.grad.clone()\n",
    "a_i.grad.zero_()\n",
    "print(\"Autograd total gradient:\", grad_autodiff)\n",
    "\n",
    "# ---- Branch decomposition ----\n",
    "# 1. Direct path: dr/da_s holding s_next constant\n",
    "dr_da_s_direct = torch.autograd.functional.jacobian(\n",
    "    lambda a_s: r_fn(a_s, s_next.detach()), a_s\n",
    ")\n",
    "\n",
    "# 2. Indirect path: dr/ds_next * ds_next/da_s\n",
    "dr_ds = torch.autograd.functional.jacobian(lambda s: r_fn(a_s.detach(), s), s_next)\n",
    "ds_da_s = torch.autograd.functional.jacobian(lambda a_s: a_s ** 2, a_s)\n",
    "indirect = dr_ds @ ds_da_s\n",
    "\n",
    "# 3. Combine\n",
    "dr_da_s_total = dr_da_s_direct + indirect\n",
    "\n",
    "# 4. Multiply by da_s/da\n",
    "da_s_da = torch.autograd.functional.jacobian(torch.sin, a_i)\n",
    "grad_formula = dr_da_s_total @ da_s_da\n",
    "\n",
    "print(\"Formula (split paths):\", grad_formula)"
   ],
   "id": "155564694d2cd070",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autograd total gradient: tensor([0.4223])\n",
      "Formula (split paths): tensor([[0.4223]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eq 13 & 14",
   "id": "41d17ed5f40252f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:29:11.639358Z",
     "start_time": "2025-09-29T14:29:11.633433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cvxpy_jacobian(problem, parameter, variable):\n",
    "    jacobian = np.zeros((variable.shape[0], parameter.shape[0]))  # 2x2 matrix for ∂cp_safe_action/∂cp_action\n",
    "    for i in range(jacobian.shape[1]):\n",
    "        parameter.delta = np.zeros(jacobian.shape[1])\n",
    "        parameter.delta[i] = 1.0\n",
    "        problem.derivative()\n",
    "        jacobian[:, i] = variable.delta\n",
    "    return jacobian"
   ],
   "id": "59c9a18e18fa2b82",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:49:08.793357Z",
     "start_time": "2025-09-29T14:49:08.731157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define (12)\n",
    "cp_action = cp.Parameter(2)\n",
    "safe_action_center = np.zeros(2)\n",
    "safe_action_generator = np.eye(2)\n",
    "\n",
    "cp_safe_action = cp.Variable(2)\n",
    "weights = cp.Variable(2)\n",
    "\n",
    "objective = cp.Minimize(cp.sum_squares(cp_action - cp_safe_action))\n",
    "\n",
    "pos_constraint = cp_safe_action - safe_action_center == safe_action_generator @ weights\n",
    "size_constraint = cp.norm(weights, \"inf\") <= 1\n",
    "constraints = [pos_constraint, size_constraint]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "\n",
    "a_s_boundary = np.array([1, 0])\n",
    "v = np.array([1, 0])\n",
    "eps = 1e-5\n",
    "for t in np.linspace(0, 1, 10):\n",
    "    a_u = a_s_boundary + t * v\n",
    "    cp_action.value = a_u\n",
    "    problem.solve(requires_grad=True)\n",
    "    # Verify (13)\n",
    "    assert np.allclose(a_s_boundary, cp_safe_action.value, atol=1e-3)\n",
    "\n",
    "\n",
    "    jacobian = cvxpy_jacobian(problem, cp_action, cp_safe_action)\n",
    "\n",
    "    upstream_gradient = np.ones_like(cp_safe_action.value)  # dr/da_s\n",
    "    assert np.allclose(upstream_gradient @ jacobian @ v, 0.0, atol=1e-5)"
   ],
   "id": "2e27288063dfc92c",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eq 15",
   "id": "6f019936163006f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:58:14.031303Z",
     "start_time": "2025-09-29T14:58:13.186885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check (15) for a bunch of random values\n",
    "\n",
    "for d in range(2, 10):\n",
    "    cp_action = cp.Parameter(d)\n",
    "    safe_action_center = np.zeros(d)\n",
    "    safe_action_generator = np.random.uniform(size=(d, 2*d)) * 0.5\n",
    "\n",
    "    cp_safe_action = cp.Variable(d)\n",
    "    weights = cp.Variable(2*d)\n",
    "\n",
    "    objective = cp.Minimize(cp.sum_squares(cp_action - cp_safe_action))\n",
    "\n",
    "    pos_constraint = cp_safe_action - safe_action_center == safe_action_generator @ weights\n",
    "    size_constraint = cp.norm(weights, \"inf\") <= 1\n",
    "    constraints = [pos_constraint, size_constraint]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    for val in np.random.uniform(size=(10, d)):\n",
    "        cp_action.value = val\n",
    "        problem.solve(requires_grad=True)\n",
    "        jacobian = cvxpy_jacobian(problem, cp_action, cp_safe_action)\n",
    "\n",
    "        if np.allclose(val, cp_safe_action.value, atol=1e-3):\n",
    "            # already safe\n",
    "            assert d == np.linalg.matrix_rank(jacobian, tol=1e-4)\n",
    "        else:\n",
    "            assert d > np.linalg.matrix_rank(jacobian, tol=1e-4)"
   ],
   "id": "ee984d72095ae9d1",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eq 17",
   "id": "1502f8fb3c4e7af9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.610352Z",
     "start_time": "2025-09-29T09:19:46.601853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "s = torch.tensor([0.1, -0.2])\n",
    "c_d = 0.5\n",
    "\n",
    "\n",
    "def l_r(a_s, s):\n",
    "    return 0.5 * torch.sum((a_s - s) ** 2)\n",
    "\n",
    "\n",
    "a_s = torch.tanh(a)\n",
    "loss = l_r(a_s, s) + c_d * torch.sum((a_s - a) ** 2)\n",
    "loss.backward()\n",
    "grad_autodiff = a.grad.clone()\n",
    "a.grad.zero_()\n",
    "\n",
    "# Manual gradient\n",
    "dl_r_da = torch.autograd.functional.jacobian(lambda a_: l_r(torch.tanh(a_), s), a)\n",
    "da_s_da = torch.diag(1 - torch.tanh(a) ** 2)  # Jacobian of tanh\n",
    "grad_manual = dl_r_da + 2 * c_d * (a_s - a).T @ (da_s_da - torch.eye(2))\n",
    "\n",
    "print(\"Automatic gradient:\", grad_autodiff)\n",
    "print(\"Manual gradient:\", grad_manual)"
   ],
   "id": "8647dfb912a07197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic gradient: tensor([0.4161, 1.0450])\n",
      "Manual gradient: tensor([0.4161, 1.0450], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222994/3143576541.py:19: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4421.)\n",
      "  grad_manual = dl_r_da + 2 * c_d * (a_s - a).T @ (da_s_da - torch.eye(2))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eq 32",
   "id": "1aaf8b56b2540c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.647797Z",
     "start_time": "2025-09-29T09:19:46.614831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define symbols\n",
    "lambda_a, lambda_As, lambda_A = sp.symbols('lambda_a lambda_As lambda_A', real=True, positive=True)\n",
    "\n",
    "# Original mapping\n",
    "omega_tanh = sp.tanh(lambda_a / lambda_As) / sp.tanh(lambda_A / lambda_As)\n",
    "\n",
    "# SymPy derivative\n",
    "domega_dlambda_a_sympy = sp.diff(omega_tanh, lambda_a)\n",
    "\n",
    "# Claimed formula\n",
    "domega_dlambda_a_claimed = (1 - sp.tanh(lambda_a / lambda_As) ** 2) / (lambda_As * sp.tanh(lambda_A / lambda_As))\n",
    "\n",
    "print(\"Difference after simplification:\", sp.simplify(domega_dlambda_a_sympy - domega_dlambda_a_claimed))"
   ],
   "id": "77d2418d6d49a68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference after simplification: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Proof of Theorem 1",
   "id": "bd32cac549d18d72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.696262Z",
     "start_time": "2025-09-29T09:19:46.666032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Symbols\n",
    "d = 3\n",
    "n = 4\n",
    "a = sp.Matrix(d, 1, lambda i, _: sp.symbols(f'a{i}'))\n",
    "a_s = sp.Matrix(d, 1, lambda i, _: sp.Function(f'a_s_{i}')(*a))\n",
    "c = sp.Matrix(sp.symbols(f'c0:{d}'))\n",
    "G = sp.Matrix(sp.symbols(f'G0:{d * n}')).reshape(d, n)\n",
    "gamma = sp.Matrix(n, 1, lambda i, _: sp.Function(f'gamma_{i}')(*a))\n",
    "z = sp.Matrix.vstack(a_s, gamma)\n",
    "Q = sp.BlockMatrix([\n",
    "    [2 * sp.eye(d), sp.zeros(d, n)],\n",
    "    [sp.zeros(n, d), sp.zeros(n, n)]\n",
    "]).as_explicit()\n",
    "q = -2 * sp.Matrix.vstack(a, sp.zeros(n, 1))\n",
    "A = sp.Matrix.hstack(sp.eye(d), -G)\n",
    "b = c\n",
    "K = sp.BlockMatrix([\n",
    "    [sp.zeros(n, d), sp.eye(n)],\n",
    "    [sp.zeros(n, d), -sp.eye(n)]\n",
    "]).as_explicit()\n",
    "h = sp.ones(2 * n, 1)\n",
    "\n",
    "dual_lambda = sp.Matrix(2 * n, 1, lambda i, _: sp.Function(f'lambda_{i}')(*a))\n",
    "dual_nu = sp.Matrix(d, 1, lambda i, _: sp.Function(f'nu_{i}')(*a))\n",
    "\n",
    "d_z = z.jacobian(a)\n",
    "d_lambda = dual_lambda.jacobian(a)\n",
    "d_nu = dual_nu.jacobian(a)\n",
    "d_a_s = a_s.jacobian(a)\n",
    "d_gamma = gamma.jacobian(a)"
   ],
   "id": "e8f91c2999abc1a0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:46.954430Z",
     "start_time": "2025-09-29T09:19:46.701271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 44\n",
    "objective_44 = (a - a_s).T * (a - a_s)\n",
    "equalities_44 = a_s - (c + G * gamma)\n",
    "inequalities_44 = sp.Matrix.vstack(gamma, -gamma) - sp.ones(2 * n, 1)\n",
    "\n",
    "# Equation 45\n",
    "objective_45 = (1 / 2) * z.T * Q * z + q.T * z\n",
    "equalities_45 = A * z - b\n",
    "inequalities_45 = K * z - h\n",
    "\n",
    "print(\"Difference of objectives (45) - (44):\", sp.simplify(objective_45 - objective_44))\n",
    "print(\"Difference of equalities (45) - (44):\", sp.simplify(equalities_45 - equalities_44))\n",
    "print(\"Difference of inequalities (45) - (44):\", sp.simplify(inequalities_45 - inequalities_44))"
   ],
   "id": "951630b837e806d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of objectives (45) - (44): Matrix([[-a0**2 - a1**2 - a2**2]])\n",
      "Difference of equalities (45) - (44): Matrix([[0], [0], [0]])\n",
      "Difference of inequalities (45) - (44): Matrix([[0], [0], [0], [0], [0], [0], [0], [0]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.017302Z",
     "start_time": "2025-09-29T09:19:46.960927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 53\n",
    "A_53 = sp.BlockMatrix([\n",
    "    [Q, K.T, A.T],\n",
    "    [sp.diag(*dual_lambda) * K, sp.diag(*(K * z - h)), sp.zeros(2 * n, d)],\n",
    "    [A, sp.zeros(d, 2 * n), sp.zeros(d, d)]\n",
    "]).as_explicit()\n",
    "x_53 = sp.Matrix.vstack(d_z, d_lambda, d_nu)\n",
    "b_53 = sp.BlockMatrix([\n",
    "    [2 * sp.eye(d)],\n",
    "    [sp.zeros(3 * n + d, d)],\n",
    "]).as_explicit()\n",
    "\n",
    "# Equation 54\n",
    "A_54 = sp.BlockMatrix([\n",
    "    [2 * sp.eye(d), sp.zeros(d, n), sp.zeros(d, 2 * n), sp.eye(d)],\n",
    "    [sp.zeros(n, d), sp.zeros(n, n), sp.BlockMatrix([sp.eye(n), -sp.eye(n)]), -G.T],\n",
    "    [sp.zeros(2 * n, d), sp.diag(*dual_lambda) * sp.BlockMatrix([[sp.eye(n)], [-sp.eye(n)]]).as_explicit(),\n",
    "     sp.BlockMatrix([[sp.diag(*gamma) - sp.eye(n), sp.zeros(n, n)],\n",
    "                     [sp.zeros(n, n), -sp.diag(*gamma) - sp.eye(n)]]).as_explicit(), sp.zeros(2 * n, d)],\n",
    "    [sp.eye(d), -G, sp.zeros(d, 2 * n), sp.zeros(d, d)]\n",
    "]).as_explicit()\n",
    "x_54 = sp.Matrix.vstack(d_a_s, d_gamma, d_lambda, d_nu)\n",
    "b_54 = b_53\n",
    "\n",
    "print(\"Difference of A (53) - (54):\", sp.simplify(A_53 - A_54))\n",
    "print(\"Difference of x (53) - (54):\", sp.simplify(x_53 - x_54))\n",
    "print(\"Difference of b (53) - (54):\", sp.simplify(b_53 - b_54))\n",
    "print(\"Shape compatibility:\", (A_54 * x_53).shape == b_53.shape)"
   ],
   "id": "5dcda84b896af271",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of A (53) - (54): Matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Difference of x (53) - (54): Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
      "Difference of b (53) - (54): Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
      "Shape compatibility: True\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.052355Z",
     "start_time": "2025-09-29T09:19:47.025596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equations (55) - (58)\n",
    "lhs_55 = 2 * d_a_s + d_nu\n",
    "rhs_55 = 2 * sp.eye(d)\n",
    "lhs_56 = sp.BlockMatrix([sp.eye(n), -sp.eye(n)]).as_explicit() * d_lambda - G.T * d_nu\n",
    "rhs_56 = sp.zeros(n, d)\n",
    "lhs_57 = sp.diag(*dual_lambda) * sp.BlockMatrix([[sp.eye(n)], [-sp.eye(n)]]).as_explicit() * d_gamma + sp.BlockMatrix(\n",
    "    [[sp.diag(*gamma) - sp.eye(n), sp.zeros(n, n)],\n",
    "     [sp.zeros(n, n), -sp.diag(*gamma) - sp.eye(n)]]).as_explicit() * d_lambda\n",
    "rhs_57 = sp.zeros(2 * n, d)\n",
    "lhs_58 = d_a_s -G * d_gamma\n",
    "rhs_58 = sp.zeros(d, d)\n",
    "print(\"Difference of A_54 * x_54  - lhs_55-lhs_58\", sp.simplify(A_54 * x_54 - sp.Matrix.vstack(lhs_55, lhs_56, lhs_57, lhs_58)))\n",
    "print(\"Difference of b_54  - rhs_55-rhs_58\", sp.simplify(b_54 - sp.Matrix.vstack(rhs_55, rhs_56, rhs_57, rhs_58)))"
   ],
   "id": "41e7d446ad40ad1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of A_54 * x_54  - lhs_55-lhs_58 Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
      "Difference of b_54  - rhs_55-rhs_58 Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.091166Z",
     "start_time": "2025-09-29T09:19:47.058340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 59\n",
    "eq_58 = sp.Eq(lhs_58, rhs_58)\n",
    "eq_59 = sp.Eq(d_a_s, G*d_gamma)\n",
    "print(\"Difference of (58) and (59)\", sp.simplify((lhs_58 - rhs_58) - (eq_59.lhs - eq_59.rhs)))"
   ],
   "id": "d43ea4006fbf935f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of (58) and (59) Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.160191Z",
     "start_time": "2025-09-29T09:19:47.096520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 60\n",
    "eq_60 = sp.Eq(d_nu, 2*sp.eye(d)-2*G*d_gamma)\n",
    "subs_dict_59 = {eq_59.lhs[i, j]: eq_59.rhs[i, j] for i in range(eq_59.lhs.rows) for j in range(eq_59.lhs.cols)}\n",
    "print(\"Difference of (55)+(59) and (60)\", sp.simplify((lhs_55 - rhs_55).subs(subs_dict_59) - (eq_60.lhs - eq_60.rhs)))"
   ],
   "id": "185d633a9144bfb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of (55)+(59) and (60) Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.834822Z",
     "start_time": "2025-09-29T09:19:47.185717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 61\n",
    "eq_61 = sp.Eq(0.5 * sp.BlockMatrix([sp.eye(n), -sp.eye(n)]).as_explicit() * d_lambda, G.T - G.T*G*d_gamma)\n",
    "subs_dict_60 = {eq_60.lhs[i, j]: eq_60.rhs[i, j] for i in range(eq_60.lhs.rows) for j in range(eq_60.lhs.cols)}\n",
    "print(\"Difference of (56)+(60) and (61)\", sp.simplify((lhs_56 - rhs_56).subs(subs_dict_60) - 2*(eq_61.lhs - eq_61.rhs)))"
   ],
   "id": "1ecc08a16523cc50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of (56)+(60) and (61) Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.844416Z",
     "start_time": "2025-09-29T09:19:47.841279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equation 63\n",
    "I_a = [0, 1]\n",
    "I_i = list(range(2,2*n))\n",
    "subs_dict_63 = {gamma[i, 0]: 1 for i in I_a} | {dual_lambda[i, 0]: 0 for i in I_i}"
   ],
   "id": "d9f198336081f6d8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:19:47.914748Z",
     "start_time": "2025-09-29T09:19:47.849174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eq_63 = sp.Eq(sp.BlockMatrix([[sp.diag(*dual_lambda[I_a,0]) * d_gamma[I_a, :]],\n",
    "                              [sp.diag(*sp.Matrix.vstack(gamma[2:, :]- sp.ones(2, 1), -gamma - sp.ones(4, 1)))*d_lambda[I_i, :] ]]).as_explicit(),sp.zeros(2*n,d))\n",
    "print(\"Difference of Indices + (57) and (63)\", sp.simplify((lhs_57 - rhs_57).subs(subs_dict_63) - (eq_63.lhs - eq_63.rhs).subs(subs_dict_63)))"
   ],
   "id": "26e675d4793d6519",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of Indices + (57) and (63) Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:29:14.793742Z",
     "start_time": "2025-09-29T14:29:14.770637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trying an example to verify (71)\n",
    "cp_action = cp.Parameter(2)\n",
    "cp_action.value = np.array([2.0, 0.0])\n",
    "\n",
    "safe_action_center = np.zeros(2)\n",
    "safe_action_generator = np.eye(2)\n",
    "\n",
    "cp_safe_action = cp.Variable(2)\n",
    "weights = cp.Variable(2)\n",
    "\n",
    "objective = cp.Minimize(cp.sum_squares(cp_action - cp_safe_action))\n",
    "\n",
    "pos_constraint = cp_safe_action - safe_action_center == safe_action_generator @ weights\n",
    "size_constraint = cp.norm(weights, \"inf\") <= 1\n",
    "constraints = [pos_constraint, size_constraint]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(requires_grad=True)\n",
    "\n",
    "inactive_generators = safe_action_generator[:, 1:2]\n",
    "expected_jacobian = inactive_generators @ np.linalg.inv(inactive_generators.T @ inactive_generators) @ inactive_generators.T\n",
    "numerical_jacobian = cvxpy_jacobian(problem, cp_action, cp_safe_action)\n",
    "\n",
    "assert np.allclose(expected_jacobian, numerical_jacobian, atol=1e-6)"
   ],
   "id": "f53d7292eeab5a90",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T07:51:53.607472Z",
     "start_time": "2025-09-30T07:51:53.329787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check (71) for a bunch of random values, fails sometimes due to numerics or being close to the border/corners where we are no actually differentiable\n",
    "\n",
    "for d in range(2, 10):\n",
    "    cp_action = cp.Parameter(d)\n",
    "    safe_action_center = np.zeros(d)\n",
    "    safe_action_generator = np.random.uniform(size=(d, 2*d)) * 0.5\n",
    "\n",
    "    cp_safe_action = cp.Variable(d)\n",
    "    weights = cp.Variable(2*d)\n",
    "\n",
    "    objective = cp.Minimize(cp.sum_squares(cp_action - cp_safe_action))\n",
    "\n",
    "    pos_constraint = cp_safe_action - safe_action_center == safe_action_generator @ weights\n",
    "    size_constraint = cp.norm(weights, \"inf\") <= 1\n",
    "    constraints = [pos_constraint, size_constraint]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    for val in np.random.uniform(size=(10, d)):\n",
    "        cp_action.value = val\n",
    "        problem.solve(requires_grad=True)\n",
    "        numerical_jacobian = cvxpy_jacobian(problem, cp_action, cp_safe_action)\n",
    "        inactive_generators = safe_action_generator[:, np.abs(weights.value) < 0.99]\n",
    "        expected_jacobian = inactive_generators @ np.linalg.pinv(inactive_generators.T @ inactive_generators) @ inactive_generators.T\n",
    "        try:\n",
    "            assert np.allclose(expected_jacobian, numerical_jacobian, atol=1e-4)\n",
    "        except AssertionError:\n",
    "            print(f\"Safe: {np.allclose(cp_action.value, cp_safe_action.value, atol=1e-3)}, dimension {d}\")\n",
    "            print(np.round(expected_jacobian, 3))\n",
    "            print(np.round(numerical_jacobian, 3))\n",
    "            print(np.round(inactive_generators, 3)) # If empty we are on a corner\n",
    "            print(np.round(cp_action.value - cp_safe_action.value, 3)) # if very small we are barely differentiable as we are close to the boundary, which makes it numerically unstable\n",
    "            raise AssertionError"
   ],
   "id": "1e381c9d87b86b3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "Safe: False, dimension 5\n",
      "[[ 0.124 -0.157  0.116  0.142  0.225]\n",
      " [-0.157  0.971  0.008  0.04   0.038]\n",
      " [ 0.116  0.008  0.539  0.47  -0.118]\n",
      " [ 0.142  0.04   0.47   0.44   0.061]\n",
      " [ 0.225  0.038 -0.118  0.061  0.925]]\n",
      "[[ 0.956 -0.012 -0.131  0.158 -0.016]\n",
      " [-0.012  0.997 -0.035  0.042 -0.004]\n",
      " [-0.131 -0.035  0.613  0.466 -0.047]\n",
      " [ 0.158  0.042  0.466  0.441  0.056]\n",
      " [-0.016 -0.004 -0.047  0.056  0.994]]\n",
      "[[0.139 0.028 0.203]\n",
      " [0.146 0.478 0.02 ]\n",
      " [0.148 0.347 0.463]\n",
      " [0.216 0.338 0.471]\n",
      " [0.43  0.05  0.268]]\n",
      "[ 0.049  0.013  0.145 -0.174  0.017]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[126]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m np.allclose(expected_jacobian, numerical_jacobian, atol=\u001B[32m1e-4\u001B[39m)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m:\n",
      "\u001B[31mAssertionError\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[126]\u001B[39m\u001B[32m, line 34\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28mprint\u001B[39m(np.round(inactive_generators, \u001B[32m3\u001B[39m)) \u001B[38;5;66;03m# If empty we are on a corner\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;28mprint\u001B[39m(np.round(cp_action.value - cp_safe_action.value, \u001B[32m3\u001B[39m)) \u001B[38;5;66;03m# if very small we are barely differentiable as we are close to the boundary, which makes it numerically unstable\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m\n",
      "\u001B[31mAssertionError\u001B[39m: "
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T07:48:24.866590Z",
     "start_time": "2025-09-30T07:48:24.859261Z"
    }
   },
   "cell_type": "code",
   "source": "cp_action.value - cp_safe_action.value",
   "id": "f5bfbaa025219d07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00422075,  0.0051669 ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a05747efbeebd5a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
